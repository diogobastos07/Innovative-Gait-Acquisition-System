# Prepare Acquisition System



## How to Use

1. **Define the Model Path**  
  Ensure the YOLO model weights file is specified correctly in the [system.yaml](../acquisition_system/configs/system.yaml). The weights file (`best.pt`) will be located in the `weights` subfolder of the directory defined by the `project` and `name` parameters in the `train_cfg` section of the [Yolo.yaml](../object_detector/Yolo/Yolo.yaml) configuration file.

2. **Run the command to start the acquisition system**
  ```
  python acquisition_system/main.py
  ```

**Note**:
The [system.yaml](../acquisition_system/configs/system.yaml) file is configured with optimized values for the video `853889-hd_1920_1080_25fps.mp4` stored in the acquisition_system/inputs/ folder.

### How to Use with a New Video
1. **Input Video Requirements**:  
Ensure the video captures people from an elevated viewpoint with a wide field of view for accurate tracking, ideally at 25fps for real-time processing.

2. **Qualitatively Evaluate Tracking Performance**:
For assessment you can set as true the parameters `save_annotated_video`, `show_annotated_frames`, `log_to_file` and `diagrams` in [system.yaml](../acquisition_system/configs/system.yaml).

3. **Adjust Tracking Configuration**:
If tracking is not satisfactory, update the `track_cfg` section in [system.yaml](../acquisition_system/configs/system.yaml). Modify parameters like `conf` and/or `iou`, select another tracker or customize it as described [here](https://docs.ultralytics.com/pt/modes/track/#tracking-arguments). If necessary, improve the object detector by increasing training iterations, batch size, or switching to a more complex YOLO version (e.g., YOLO11s).

4. **Tune SQAM Parameters**:
First, adjust `n`, `p`, `x`, and `t` in `sqam_cfg` section to meet your goals, respecting the following constraints:
>   * 2 ≤ `p` < `n`
>   * 1 ≤ `t`
>   * 2 ≤ `x` ≤ `n`/2
>   * `x`⋅`t` ≤ `n` 
Next, adjust `d` to limit fluctuations in the direction of movement and `v` to define the minimum allowed speed. Finally, fine-tune `camera_dist` to ensure accurate calculation of trajectory angles.

5. **Process Valid Sequences**:
Implement or customize how valid sequences (those meeting all criteria) are handled in the `use_valid_data()` function of the [SQAM class](../acquisition_system/classes/sqam.py).


## Detailed Config

### general_cfg
* General Configuration
>
>   * Args
>       * model_path: Path to the YOLO model's weights file.
>       * input_video_path: Path to the input video file to be processed for the acquisition system.
>       * name: A unique identifier for the current session, used for naming output videos if `save_annotated_video: true`.
>       * save_annotated_video: If `True`, the video specified in `input_video_path` is saved with annotated bounding boxes and tracking details. The default path is: outputs/<acquisition_system>/<annotated_video>/<name>.mp4.
>       * show_annotated_frames: If `True`, it displays annotated frames in real time during processing.
>       * log_to_file: If `True`, it logs tracking and system details into a file. The default path is: outputs/<acquisition_system>/<logs>/<Datetime>.txt.
----

### track_cfg
* Track Configuration
>
>   * Args
>       * tracker: By default, the `track()` function uses `tracker=botsort.yaml` as the tracking algorithm, but also accepts `tracker=bytetrack.yaml`
>       * [Predict Arguments Documentation](https://docs.ultralytics.com/modes/predict/#inference-arguments): The arguments for the `track()` function are identical to those for the `predict()` function.     
>
>**Note:**
>Learn more about YOLO's tracking capabilities in [Track Documentation](https://docs.ultralytics.com/modes/track/). The `track()` function is utilized in the acquisition system following the structure demonstrated in the [Persisting Tracks Loop](https://docs.ultralytics.com/pt/modes/track/#persisting-tracks-loop) example. It uses `frame` and `persist=True` as initial arguments, but additional arguments can be specified in this `track_cfg` configuration section.
----

### sqam_cfg
* SQAM Configuration
>
>   * Args
>       * n: Total frames required for the sequence to be considered complete.
>       * p: Minimum number of frames required to start evaluating direction changes.
>       * x: Number of consecutive frames considered in speed calculation.
>       * t: Number of frame intervals used to calculate the average speed.
>       * d: Limit of distance allowed between the new point and the trend line.
>       * v: Minimum limit allowed for average speeds.
>       * camera_dist: Estimated distance (in pixels) between the camera and the tracking plane, used to calculate trajectory angles.
>       * diagrams: If `True`, two data diagrams are saved with respective legends to results visualization.
----

### Example
```yaml
general_cfg:
  model_path: outputs/object_detector/train/yolo11n/weights/best.pt
  input_video_path: acquisition_system/inputs/853889-hd_1920_1080_25fps.mp4
  name: 853889-hd_1920_1080_25fps
  save_annotated_video: true
  show_annotated_frames: false # not recommended for real-time processing due to delays
  log_to_file: true

track_cfg:
  tracker: bytetrack.yaml
  conf: 0.55
  iou: 0.7
  device: 0
 
sqam_cfg:
  n: 75
  p: 10
  x: 5
  t: 3
  d: 15
  v: 0.025
  camera_dist: 920
  diagrams: true
```

**Tip**: