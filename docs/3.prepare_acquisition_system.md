# Prepare Acquisition System

## Gait Sequence Acquisition
This gait sequence acquisition system ensures data consistency throughout the walking sequence to effectively store gait sequence samples, which can, for example, directly improve gait recognition rate. In this approach, data quality is prioritized over quantity, avoiding the storage of noisy gait data that could hinder accurate identification.

### Exclusion Criteria  

| **Reason**                 | **Description**                                                                 | **Controlled by** |
|----------------------------|---------------------------------------------------------------------------------|-------------------|
| üõë **No movement**         | Significant movement is required to extract gait characteristics.               |SQAM              |
| ‚ùå **Body parts out of view** | Legs/feet out of the camera view compromise gait analysis.                  |YOLO               |
| ‚Ü©Ô∏è **Direction changes**   | Abrupt orientation changes disrupt gait modeling.                               |SQAM              |
| üïí **Frame discontinuity**  | Missing frames cause loss of critical temporal information.                    |SQAM              |
| üöß **Occluded body**        | Obstructions by objects/people compromise gait acquisition.                     |YOLO             |
| ‚è≥ **Short acquisition**    | Limited capture time reduces data available for accurate identification.       |SQAM              |


## How to Use

1. **Define the Model Path**  
  Ensure the YOLO model weights file is specified correctly in the [system.yaml](../acquisition_system/configs/system.yaml). The weights file (`best.pt`) will be located in the `weights` subfolder of the directory defined by the `project` and `name` parameters in the `train_cfg` section of the [Yolo.yaml](../object_detector/Yolo/Yolo.yaml) configuration file.

2. **Run the command to start the acquisition system**
  ```
  python acquisition_system/main.py
  ```

  **Note**:
  The [system.yaml](../acquisition_system/configs/system.yaml) file is configured with optimized values for the video `853889-hd_1920_1080_25fps.mp4` stored in the acquisition_system/inputs/ folder.

### How to Use with a New Video
1. **Input Video Requirements**  
  Ensure the video captures people from an elevated viewpoint with a wide field of view for accurate tracking, ideally at 25fps for real-time processing.

2. **Qualitatively Evaluate Tracking Performance**<br>
  For assessment you can set as true the parameters `save_annotated_video`, `show_annotated_frames`, `log_to_file` and `diagrams` in [system.yaml](../acquisition_system/configs/system.yaml).

3. **Adjust Tracking Configuration**
  
  If tracking is not satisfactory, update the `track_cfg` section in [system.yaml](../acquisition_system/configs/system.yaml). Modify parameters like `conf` and/or `iou`, select another tracker or customize it as described [here](https://docs.ultralytics.com/pt/modes/track/#tracking-arguments). If necessary, improve the object detector by increasing training iterations, batch size, or switching to a more complex YOLO version (e.g., YOLO11s).

4. **Tune SQAM Parameters**
  
  First, adjust `n`, `p`, `x`, and `t` in `sqam_cfg` section to meet your goals, respecting the following constraints:

    - 2 ‚â§ `p` < `n`
    - 1 ‚â§ `t`
    - 2 ‚â§ `x` ‚â§ `n`/2
    - `x`‚ãÖ`t` ‚â§ `n`

  Next, adjust `d` to limit fluctuations in the direction of movement and `v` to define the minimum allowed speed. Finally, fine-tune `camera_dist` to ensure accurate calculation of trajectory angles.

5. **Process Valid Sequences**
  
  Implement or customize how valid sequences (those meeting all criteria) are handled in the `use_valid_data()` function of the [SQAM](../acquisition_system/classes/sqam.py) class.


## Detailed Config

### general_cfg
* General Configuration
>
>   * Args
>       * model_path: Path to the YOLO model's weights file.
>       * input_video_path: Path to the input video file to be processed for the acquisition system.
>       * name: A unique identifier for the current session, used for naming output videos if `save_annotated_video: true`.
>       * save_annotated_video: If `True`, the video specified in `input_video_path` is saved with annotated bounding boxes and tracking details. The default path is: outputs/<acquisition_system>/<annotated_video>/<name>.mp4.
>       * show_annotated_frames: If `True`, it displays annotated frames in real time during processing.
>       * log_to_file: If `True`, it logs tracking and system details into a file. The default path is: outputs/<acquisition_system>/<logs>/<Datetime>.txt.
----

### track_cfg
* Track Configuration
>
>   * Args
>       * tracker: By default, the `track()` function uses `tracker=botsort.yaml` as the tracking algorithm, but also accepts `tracker=bytetrack.yaml`
>       * [Predict Arguments Documentation](https://docs.ultralytics.com/modes/predict/#inference-arguments): The arguments for the `track()` function are identical to those for the `predict()` function.     
>
>**Note:**
>Learn more about YOLO's tracking capabilities in [Track Documentation](https://docs.ultralytics.com/modes/track/). The `track()` function is utilized in the acquisition system following the structure demonstrated in the [Persisting Tracks Loop](https://docs.ultralytics.com/pt/modes/track/#persisting-tracks-loop) example. It uses `frame` and `persist=True` as initial arguments, but additional arguments can be specified in this `track_cfg` configuration section.
----

### sqam_cfg
* SQAM Configuration
>
>   * Args
>       * n: Total frames required for the sequence to be considered complete.
>       * p: Minimum number of frames required to start evaluating direction changes.
>       * x: Number of consecutive frames considered in speed calculation.
>       * t: Number of frame intervals used to calculate the average speed.
>       * d: Limit of distance allowed between the new point and the trend line.
>       * v: Minimum limit allowed for average speeds.
>       * camera_dist: Estimated distance (in pixels) between the camera and the tracking plane, used to calculate trajectory angles.
>       * diagrams: If `True`, two data diagrams are saved with respective legends to results visualization.
----

### Example
```yaml
general_cfg:
  model_path: outputs/object_detector/train/yolo11n/weights/best.pt
  input_video_path: acquisition_system/inputs/853889-hd_1920_1080_25fps.mp4
  name: 853889-hd_1920_1080_25fps
  save_annotated_video: true
  show_annotated_frames: false # not recommended for real-time processing due to delays
  log_to_file: true

track_cfg:
  tracker: bytetrack.yaml
  conf: 0.55
  iou: 0.7
  device: 0
 
sqam_cfg:
  n: 75
  p: 10
  x: 5
  t: 3
  d: 15
  v: 0.025
  camera_dist: 920
  diagrams: true
```

**Tip**: